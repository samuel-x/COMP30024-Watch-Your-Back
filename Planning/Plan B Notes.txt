Machine Learning
	Reinforcement learning
		Q-Learning
			Section 13.3 (pg 373) in Machine Learning by Tom M. Mitchell (ML TMM.)

	Temporal Difference Learning
		Section 13.5 (pg 383) in ML TMM.
		Seems to be too much like MCTS and so has the same issues.

	Libraries
		Shogun
		TensorFlow
		Sci-kit Learn

Non-machine learning
	Alpha-beta Pruning
		Section 5.3 (pg 167) in AI book.
		Work on a way to manage time.
			Each round can spend REMAINING_TIME / num_expected_rounds
			How to estimate num_expected rounds?
			Once out of time, choose move with best alpha-beta value at that moment.
	SSS*
		https://en.wikipedia.org/wiki/SSS*
	Principal Variation Search aka NegaScout
		https://en.wikipedia.org/wiki/Principal_variation_search
		Apparently performs better than both Alpha-beta and SSS*, at the expense of more space.


Heuristics
	Try genetic algorithms after heuristics have been implemented to discover best weights.
	Mobility (number of available moves)
	Cohesiveness (number of allied neighbors)
		Take into account pieces two moves away e.g. W - W?
		Make the "cohesiveness" continuous? e.g. average distance to allied pieces